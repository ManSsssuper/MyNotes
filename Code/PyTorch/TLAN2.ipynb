{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_sbases(sbases):\n",
    "    sbases=[torch.unsqueeze(sbase,1) for sbase in sbases]\n",
    "    cats=torch.cat(sbases,1)\n",
    "    return cats\n",
    "def matmul(bases,attens):\n",
    "    outs=None\n",
    "    bases.transpose_(1,2)\n",
    "    for i in range(bases.size(0)):\n",
    "        out=torch.mm(bases[i],attens[i]).unsqueeze(0)\n",
    "        if outs==None:\n",
    "            outs=out\n",
    "        else:\n",
    "            outs=torch.cat(outs,out,0)\n",
    "    return outs.squeeze()\n",
    "class TLANet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 num_tasks,\n",
    "                 num_units_shared,\n",
    "                 num_nuits_sbases,\n",
    "                 num_units_experts,\n",
    "                 num_sbases,\n",
    "                 num_experts,\n",
    "                 use_expert_b=True,\n",
    "                 use_sbase_b=True,\n",
    "                 use_l1att_b=True,\n",
    "                 use_l2att_b=True,\n",
    "                ):\n",
    "        super(TLANet,self).__init__()\n",
    "        self.num_tasks=num_tasks\n",
    "        self.num_units_shared=num_units_shared\n",
    "        self.num_nuits_sbases=num_nuits_sbases\n",
    "        self.num_units_experts=num_units_experts\n",
    "        self.num_experts=num_experts\n",
    "        self.num_sbases=num_sbases\n",
    "        self.use_expert_b=use_expert_b\n",
    "        self.use_sbase_b=use_sbase_b\n",
    "        self.use_l1att_b=use_l1att_b\n",
    "        self.use_l2att_b=use_l2att_b\n",
    "        \n",
    "        #根据传入的参数定义层\n",
    "        #共享基\n",
    "        self.sbases=[]\n",
    "        input_dimension=input_shape[-1]\n",
    "        for i in range(num_sbases):\n",
    "            if i ==0:\n",
    "                self.sbases.append(nn.Linear(input_dimension,num_nuits_sbases,bias=use_sbase_b))\n",
    "            else :\n",
    "                self.sbases.append(nn.Linear(num_nuits_sbases,num_nuits_sbases,bias=use_sbase_b))\n",
    "        \n",
    "        self.shared=nn.Linear(num_nuits_sbases,num_units_shared,bias=use_sbase_b)\n",
    "        self.experts=[nn.Linear(num_nuits_sbases,num_units_experts,bias=use_expert_b) for i in range(num_tasks)]\n",
    "        self.l1atts=[nn.Linear(num_nuits_sbases,num_nuits_sbases,bias=use_l1att_b) for i in range(num_experts)]\n",
    "        self.l2atts=[nn.Linear(num_units_experts,num_units_experts,bias=use_l2att_b) for i in range(num_tasks)]\n",
    "        \n",
    "        self.l1att2experts_ws=[nn.Linear(num_nuits_sbases,1) for i in range(num_experts)]\n",
    "        self.l2att2tasks_ws=[nn.Linear(num_units_experts,1) for i in range(num_tasks)]\n",
    "    def forward(self,x):\n",
    "        sbs=[]\n",
    "        experts=None\n",
    "        for sbase in self.sbases:\n",
    "            x=sbase(x)\n",
    "            x=F.relu(x)\n",
    "            sbs.append(x)\n",
    "        x=self.shared(x)\n",
    "        x=F.relu(x)\n",
    "        experts=shared.unsqueeze(1)\n",
    "        cat_sbases=cat_sbases(sbs)\n",
    "\n",
    "        for i in range(self.num_experts):\n",
    "            y=l1atts[i](cat_sbases)\n",
    "            y=F.tanh(y)\n",
    "            y=l1att2experts_ws[i](y)\n",
    "            y=F.softmax(y,dim=1)\n",
    "            y=matmul(cat_sbases,y)\n",
    "            \n",
    "            expert=self.experts[i](y)\n",
    "            expert=F.relu(expert)\n",
    "            if experts==None:\n",
    "                experts=expert.unsqueeze(1)\n",
    "            else:\n",
    "                experts=torch.cat(experts,expert.unsqueeze(1),1)\n",
    "\n",
    "        outputs=[]\n",
    "        for i in range(self.num_tasks):\n",
    "            z=l2atts[i](experts)\n",
    "            z=F.tanh(z)\n",
    "            z=l2att2tasks_ws[i](z)\n",
    "            z=F.softmax(z,dim=1)\n",
    "            z=matmul(experts,z)\n",
    "            outputs.append(z)\n",
    "        return outputs\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=TLANet((100,200),3,10,10,10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLANet(\n",
      "  (shared): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
