{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#感知机实现\n",
    "import numpy as np\n",
    "X=np.array([[1, 1], [3, 3], [4, 3]])\n",
    "y=[-1,1,1]\n",
    "class Perceptron(object):\n",
    "    def __init__(self,learninig_rate=1):\n",
    "        self.w=np.array([0,0]).reshape((-1,1))\n",
    "        self.b=0\n",
    "    def sign(self,x):\n",
    "        return -1 if x <0 else +1\n",
    "    def calculate(self,X):\n",
    "        yH=np.matmul(X,self.w)+self.b\n",
    "        return np.apply_along_axis(self.sign,1,yH)\n",
    "    def get_wrong(self,X,yH,Y):\n",
    "        for x,yh,y in zip(X,yH,Y):\n",
    "            if yh!=y:\n",
    "                return {'x':x,'y':y}\n",
    "        return None\n",
    "    def fit(self,X,y):\n",
    "        while True:\n",
    "            yH=self.calculate(X)\n",
    "            wrong=self.get_wrong(X,yH,y)\n",
    "            print(wrong)\n",
    "            if not wrong:\n",
    "                break\n",
    "            self.w = self.w + (wrong['x'] * wrong['y']).reshape((-1, 1))\n",
    "            self.b = self.b + wrong['y']\n",
    "            print(f\"update w to {self.w} update b to {self.b}\")\n",
    "per=Perceptron()\n",
    "per.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN源码实现\n",
    "'''\n",
    "k近邻（kNN）算法的工作机制比较简单，根据某种距离测度找出距离给定待测样本距离最小的k个训练样本，根据k个训练样本进行预测。\n",
    "分类问题：k个点中出现频率最高的类别作为待测样本的类别\n",
    "回归问题：通常以k个训练样本的平均值作为待测样本的预测值\n",
    "kNN模型三要素：距离测度、k值的选择、分类或回归决策方式\n",
    "'''\n",
    "import numpy as np\n",
    "class KNNClassfier(object):\n",
    "\n",
    "    def __init__(self, k=5, distance='euc'):\n",
    "        self.k = k\n",
    "        self.distance = distance\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    def fit(self,X, Y):\n",
    "        '''\n",
    "        X : array-like [n_samples,shape]\n",
    "        Y : array-like [n_samples,1]\n",
    "        '''        \n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "    def predict(self,X_test):\n",
    "        '''\n",
    "        X_test : array-like [n_samples,shape]\n",
    "        Y_test : array-like [n_samples,1]\n",
    "        output : array-like [n_samples,1]\n",
    "        '''  \n",
    "        output = np.zeros((X_test.shape[0],1))\n",
    "        for i in range(X_test.shape[0]):\n",
    "            dis = [] \n",
    "            for j in range(self.x.shape[0]):\n",
    "                if self.distance == 'euc': # 欧式距离\n",
    "                    dis.append(np.linalg.norm(X_test[i]-self.x[j,:]))\n",
    "            labels = []\n",
    "            index=sorted(range(len(dis)), key=dis.__getitem__)\n",
    "            for j in range(self.k):\n",
    "                labels.append(self.y[index[j]])\n",
    "            counts = []\n",
    "            for label in labels:\n",
    "                counts.append(labels.count(label))\n",
    "            output[i] = labels[np.argmax(counts)]\n",
    "        return output\n",
    "    def score(self,x,y):\n",
    "        pred = self.predict(x)\n",
    "        err = 0.0\n",
    "        for i in range(x.shape[0]):\n",
    "            if pred[i]!=y[i]:\n",
    "                err = err+1\n",
    "        return 1-float(err/x.shape[0])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from sklearn import datasets\n",
    "    iris = datasets.load_iris()\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    # x = np.array([[0.5,0.4],[0.1,0.2],[0.7,0.8],[0.2,0.1],[0.4,0.6],[0.9,0.9],[1,1]]).reshape(-1,2)\n",
    "    # y = np.array([0,1,0,1,0,1,1]).reshape(-1,1)\n",
    "    clf = KNNClassfier(k=3)\n",
    "    clf.fit(x,y)\n",
    "    print('myknn score:',clf.score(x,y))\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf_sklearn = KNeighborsClassifier(n_neighbors=3)\n",
    "    clf_sklearn.fit(x,y)\n",
    "    print('sklearn score:',clf_sklearn.score(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection  import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#读取鸢尾花数据集\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "k_range = range(1, 31)\n",
    "k_error = []\n",
    "#循环，取k=1到k=31，查看误差效果\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    #cv参数决定数据集划分比例，这里是按照5:1划分训练集和测试集\n",
    "    scores = cross_val_score(knn, x, y, cv=6, scoring='accuracy')\n",
    "    k_error.append(1 - scores.mean())\n",
    "\n",
    "#画图，x轴为k值，y值为误差值\n",
    "plt.plot(k_range, k_error)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN画图\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "n_neighbors = 11\n",
    "\n",
    "# 导入一些要玩的数据\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, :2]  # 我们只采用前两个feature,方便画图在二维平面显示\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "h = .02  # 网格中的步长\n",
    "\n",
    "# 创建彩色的图\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "\n",
    "#weights是KNN模型中的一个参数，上述参数介绍中有介绍，这里绘制两种权重参数下KNN的效果图\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # 创建了一个knn分类器的实例，并拟合数据。\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    # 绘制决策边界。为此，我们将为每个分配一个颜色\n",
    "    # 来绘制网格中的点 [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # 将结果放入一个彩色图中\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # 绘制训练点\n",
    "    plt.scatter(x[:, 0], x[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KDTree\n",
    "#!/usr/bin/python\n",
    "# -*-coding:utf-8-*-\n",
    "\n",
    "from collections import namedtuple\n",
    "from operator import itemgetter\n",
    "from pprint import pformat\n",
    "\n",
    "# 节点类,（namedtuple）Node中包含样本点和左右叶子节点\n",
    "class Node(namedtuple('Node', 'location left_child right_child')):\n",
    "    def __repr__(self):\n",
    "        return pformat(tuple(self))\n",
    "\n",
    "# 构造kd树\n",
    "def kdtree(point_list, depth=0):\n",
    "    try:\n",
    "        # 假设所有点都具有相同的维度\n",
    "        k = len(point_list[0])\n",
    "    # 如果不是point_list返回None\n",
    "    except IndexError as e:\n",
    "        return None\n",
    "    # 根据深度选择轴，以便轴循环所有有效值\n",
    "    axis = depth % k\n",
    "\n",
    "    # 排序点列表并选择中位数作为主元素\n",
    "    point_list.sort(key=itemgetter(axis))\n",
    "    # 向下取整\n",
    "    median = len(point_list) // 2\n",
    "\n",
    "    # 创建节点并构建子树\n",
    "    return Node(\n",
    "        location=point_list[median],\n",
    "        left_child=kdtree(point_list[:median], depth + 1),\n",
    "        right_child=kdtree(point_list[median + 1:], depth + 1))\n",
    "\n",
    "def main():\n",
    "    point_list = [(2, 3), (5, 4), (9, 6), (4, 7), (8, 1), (7, 2)]\n",
    "    tree = kdtree(point_list)\n",
    "    print(tree)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KD树sklearn\n",
    "#!/usr/bin/python\n",
    "# -*-coding:utf-8-*-\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.array([(2, 3), (5, 4), (9, 6), (4, 7), (8, 1), (7, 2)])\n",
    "tree = KDTree(X, leaf_size=2)\n",
    "# ind：最近的3个邻居的索引\n",
    "# dist：距离最近的3个邻居\n",
    "# [X[2]]:搜索点\n",
    "dist, ind = tree.query([X[2]], k=3)\n",
    "\n",
    "print('ind:',ind)\n",
    "print('dist:',dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB\n",
    "# Example of Naive Bayes implemented from Scratch in Python\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "def loadCsv(filename):\n",
    "    lines = csv.reader(open(filename, \"rb\"))\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset\n",
    "\n",
    "def splitDataset(dataset, splitRatio):\n",
    "    trainSize = int(len(dataset) * splitRatio)\n",
    "    trainSet = []\n",
    "    copy = list(dataset)\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(copy))\n",
    "        trainSet.append(copy.pop(index))\n",
    "    return [trainSet, copy]\n",
    "\n",
    "def separateByClass(dataset):\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def summarize(dataset):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "    del summaries[-1]\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.iteritems():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries\n",
    "\n",
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "def calculateClassProbabilities(summaries, inputVector):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.iteritems():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = inputVector[i]\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities\n",
    "            \n",
    "def predict(summaries, inputVector):\n",
    "    probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.iteritems():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    "\n",
    "def getPredictions(summaries, testSet):\n",
    "    predictions = []\n",
    "    for i in range(len(testSet)):\n",
    "        result = predict(summaries, testSet[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        if testSet[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "def main():\n",
    "    filename = 'pima-indians-diabetes.data.csv'\n",
    "    splitRatio = 0.67\n",
    "    dataset = loadCsv(filename)\n",
    "    trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    print('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(trainingSet), len(testSet))\n",
    "    # prepare model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    # test model\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: {0}%').format(accuracy)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearnNB\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 读取数据\n",
    "X = []\n",
    "Y = []\n",
    "fr = open(\"datingTestSet.txt\")\n",
    "index = 0\n",
    "for line in fr.readlines():\n",
    "    line = line.strip()\n",
    "    line = line.split('\\t')\n",
    "    X.append(line[:3])\n",
    "    Y.append(line[-1])\n",
    "\n",
    "#归一化\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 交叉分类\n",
    "train_X,test_X, train_y, test_y = train_test_split(X,\n",
    "                                                   Y,\n",
    "                                                   test_size=0.2) # test_size:测试集比例20%\n",
    "\n",
    "# KNN模型，选择3个邻居\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "print(model)\n",
    "\n",
    "expected = test_y\n",
    "predicted = model.predict(test_X)\n",
    "print(metrics.classification_report(expected, predicted))       # 输出分类信息\n",
    "label = list(set(Y))    # 去重复，得到标签类别\n",
    "print(metrics.confusion_matrix(expected, predicted, labels=label))  # 输出混淆矩阵信息\n",
    "#共有三种\n",
    "#多项式：做平滑，同统计学习方法中\n",
    "#高斯贝叶斯：适合连续特征（正态分布计算条件概率）\n",
    "#伯努利：适合离散特征，都是在计算条件概率时具有差异\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
